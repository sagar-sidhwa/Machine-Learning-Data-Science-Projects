{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04451425-c814-43e6-b797-f9252ba5266e",
   "metadata": {},
   "source": [
    "# üìù Project Title - LLM & RAG-Powered Medical Transcription Summarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ec98e1-8609-4e83-97f7-df3a98974456",
   "metadata": {},
   "source": [
    "# üìñ Project Description\n",
    "- This project aims to revolutionize how healthcare professionals interact with medical transcription data. Using the power of Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG), the system provides intelligent summarization of patient records.\n",
    "- It simulates how nurses or doctors can automatically get health summaries before a check-up, using historical descriptions, specialties, and keywords.\n",
    "- Additionally, the system is built to evolve ‚Äî new transcriptions update the vector database, enabling real-time context-aware answers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe178aa9-eee3-471f-9965-d99ef72c3d47",
   "metadata": {},
   "source": [
    "## üß± Notebook Structure & Sections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b389161-27f7-463a-a6f4-8a629539a269",
   "metadata": {},
   "source": [
    "### ‚úÖ 1. Importing Required Libraries\n",
    "- Start by importing essential libraries (pandas, numpy, seaborn, sklearn, xgboost, lightgbm, matplotlib, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33a737b6-1ea8-4026-9abf-2bbf57ab5734",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers import pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b7eb2c-1596-4209-9a75-5331b1cb2d56",
   "metadata": {},
   "source": [
    "### üîç 2. Data Loading and Overview\n",
    "- Loaded ~5,000 rows of transcription records.\n",
    "- Columns include description, transcription, medical_specialty, sample_name, and keywords.\n",
    "- ‚úÖ Cleaned missing values and identified description as the key input for building summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e72910a-f694-4274-a2f6-2ae1ad55498b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('mtsamples.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3da946d-cbf7-4a0c-992e-76e8c650d54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = 'Unnamed: 0', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1cfc572-720d-411a-bcd0-4cf912237949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>sample_name</th>\n",
       "      <th>transcription</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A 23-year-old white female presents with comp...</td>\n",
       "      <td>Allergy / Immunology</td>\n",
       "      <td>Allergic Rhinitis</td>\n",
       "      <td>SUBJECTIVE:,  This 23-year-old white female pr...</td>\n",
       "      <td>allergy / immunology, allergic rhinitis, aller...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Consult for laparoscopic gastric bypass.</td>\n",
       "      <td>Bariatrics</td>\n",
       "      <td>Laparoscopic Gastric Bypass Consult - 2</td>\n",
       "      <td>PAST MEDICAL HISTORY:, He has difficulty climb...</td>\n",
       "      <td>bariatrics, laparoscopic gastric bypass, weigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Consult for laparoscopic gastric bypass.</td>\n",
       "      <td>Bariatrics</td>\n",
       "      <td>Laparoscopic Gastric Bypass Consult - 1</td>\n",
       "      <td>HISTORY OF PRESENT ILLNESS: , I have seen ABC ...</td>\n",
       "      <td>bariatrics, laparoscopic gastric bypass, heart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2-D M-Mode. Doppler.</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2-D Echocardiogram - 1</td>\n",
       "      <td>2-D M-MODE: , ,1.  Left atrial enlargement wit...</td>\n",
       "      <td>cardiovascular / pulmonary, 2-d m-mode, dopple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2-D Echocardiogram</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2-D Echocardiogram - 2</td>\n",
       "      <td>1.  The left ventricular cavity size and wall ...</td>\n",
       "      <td>cardiovascular / pulmonary, 2-d, doppler, echo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  \\\n",
       "0   A 23-year-old white female presents with comp...   \n",
       "1           Consult for laparoscopic gastric bypass.   \n",
       "2           Consult for laparoscopic gastric bypass.   \n",
       "3                             2-D M-Mode. Doppler.     \n",
       "4                                 2-D Echocardiogram   \n",
       "\n",
       "             medical_specialty                                sample_name  \\\n",
       "0         Allergy / Immunology                         Allergic Rhinitis    \n",
       "1                   Bariatrics   Laparoscopic Gastric Bypass Consult - 2    \n",
       "2                   Bariatrics   Laparoscopic Gastric Bypass Consult - 1    \n",
       "3   Cardiovascular / Pulmonary                    2-D Echocardiogram - 1    \n",
       "4   Cardiovascular / Pulmonary                    2-D Echocardiogram - 2    \n",
       "\n",
       "                                       transcription  \\\n",
       "0  SUBJECTIVE:,  This 23-year-old white female pr...   \n",
       "1  PAST MEDICAL HISTORY:, He has difficulty climb...   \n",
       "2  HISTORY OF PRESENT ILLNESS: , I have seen ABC ...   \n",
       "3  2-D M-MODE: , ,1.  Left atrial enlargement wit...   \n",
       "4  1.  The left ventricular cavity size and wall ...   \n",
       "\n",
       "                                            keywords  \n",
       "0  allergy / immunology, allergic rhinitis, aller...  \n",
       "1  bariatrics, laparoscopic gastric bypass, weigh...  \n",
       "2  bariatrics, laparoscopic gastric bypass, heart...  \n",
       "3  cardiovascular / pulmonary, 2-d m-mode, dopple...  \n",
       "4  cardiovascular / pulmonary, 2-d, doppler, echo...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4249f25f-cfe1-498c-9f6d-b580131acc28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4999 entries, 0 to 4998\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   description        4999 non-null   object\n",
      " 1   medical_specialty  4999 non-null   object\n",
      " 2   sample_name        4999 non-null   object\n",
      " 3   transcription      4966 non-null   object\n",
      " 4   keywords           3931 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 195.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e771fc31-f3a9-4eeb-bc37-acd8684341ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping Missing Transactions\n",
    "df = df[df['transcription'].notna()].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbd0bd38-bede-49c9-848c-78da1d7370d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['full_text'] = df['description'] + df['transcription']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea63a77-10d8-4677-aebc-5bdabf9c2248",
   "metadata": {},
   "source": [
    "### ‚ú® 3. Summarization uaing (LLM + RAG) - Method(1)\n",
    "- Applied a base OpenAI GPT or similar LLM directly on the description column.\n",
    "- Used this for naive one-by-one summarization (just a baseline step)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453edf5a-8536-42fd-aa3c-474aeb220fab",
   "metadata": {},
   "source": [
    "### ü§ñ 3.1 RAG-Based Pipeline (Main Implementation)\n",
    "- Retrieval-Augmented Generation (RAG) was built using the following steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2db1377-03b2-48b7-b9ed-c1996a06ab06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method 1 - LLM + RAG (Retrieval-Augmented Generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc69ea85-c03b-4a13-9212-f2adb701e0be",
   "metadata": {},
   "source": [
    "#### üß† Step 1: Text Embedding + Vector DB Creation\n",
    "- Used sentence-transformers (e.g., all-MiniLM-L6-v2) to embed the description column.\n",
    "- Created a FAISS vector store from these embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66894961-b368-482a-8d2e-c61089537961",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df4a441e-b6b4-468c-be37-c468ad5a89ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b029deceb76e42e180e07028c8178f3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/156 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "documents = df['full_text'].tolist()\n",
    "embeddings = model.encode(documents,show_progress_bar = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60a5ddf3-a6b3-4c35-aa5f-5bf7deb72b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.IndexFlatL2(embeddings[0].shape[0])\n",
    "index.add(np.array(embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96343971-a42f-42eb-bc3f-5b228d253552",
   "metadata": {},
   "source": [
    "#### üßæ Step 2: Query + Retrieval\n",
    "- Sample question passed (e.g., ‚ÄúSummarize the patient‚Äôs history for cardiovascular cases‚Äù).\n",
    "- FAISS finds top-k relevant descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36f5220b-3851-4f24-af24-33a70746db50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "llm_rag = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\", max_new_tokens=200) #Setting max tokens set to 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "179aede4-ad0e-4420-ad24-a0cc9521e817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_query(user_query, top_k = 3):\n",
    "    query_vector = model.encode([user_query])\n",
    "    D,I = index.search(np.array(query_vector),top_k)\n",
    "    context = '\\n\\n'.join([documents[i] for i in I[0]])\n",
    "    '''\n",
    "    if len(context.split()) > 1024:\n",
    "        context = ' '.join(context.split()[:1024])\n",
    "    '''\n",
    "    prompt = f\"Context:\\n{context}\\n\\nQuestion:\\n{user_query}\\n\\nAnswer:\"\n",
    "    response = llm_rag(prompt,max_new_tokens = 300)[0]['generated_text'] # # Overrides the default max_new_tokens=200 to 300 for this specific call\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6243939-28f4-4cc2-8248-a8d1a874e7ad",
   "metadata": {},
   "source": [
    "#### üìò Step 3: LLM Generation\n",
    "- Sent retrieved descriptions as context to the LLM.\n",
    "- LLM generated a personalized summary using context + query ‚Üí this is true RAG in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70ce92d1-8201-4443-a5b6-070bc19b5672",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (4128 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fever\n"
     ]
    }
   ],
   "source": [
    "print(rag_query(\"What are the symptoms for this condition Allergic Rhinitis\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14c4889f-fb72-4543-8435-a6f9fdb1da52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The patient is a 69-year-old male who has a history of atrial fibrillation, hypertension, and hyperlipidemia.\n"
     ]
    }
   ],
   "source": [
    "print(rag_query(\"Summarize the patient‚Äôs history for cardiovascular cases\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e052299b-c921-4aef-a45b-a662c79bda99",
   "metadata": {},
   "source": [
    "### üöÄ 4. Fine-Tuning LLM an Optimized Lightweight Execution\n",
    "In this approach, we fine-tune a lightweight pretrained language model (such as `t5-small`) on our own domain-specific dataset (e.g., medical transcripts or summaries). This allows the model to learn patterns unique to our data and improve its performance on similar tasks.\n",
    "- Using local LLMs like TinyLLaMA, Phi, or GPT4All for MacBooks without GPU.\n",
    "- Created a structure for fine-tuning or prompting smaller models later.\n",
    "\n",
    "#### ‚úÖ Steps Involved:\n",
    "\n",
    "#### Step 4.1 üì¶ Install Required Packages\n",
    "```bash\n",
    "pip install transformers datasets peft accelerate sentencepiece bitsandbytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab6bcefd-120f-4d3c-a9a9-9421ae71a285",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method 2 - Fine Tune an Existing LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e91f1b-c47f-44ce-9c79-306476ffe1e3",
   "metadata": {},
   "source": [
    "#### Step 4.2 üßπ Prepare Dataset\n",
    "- Format your data into two columns:\n",
    "- full_text: The input prompt or context\n",
    "- target_text: The desired output or summary\n",
    "- Optionally create a placeholder summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65fa8e2f-8bb0-46e2-9783-4147b9f44ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target_text'] = df['full_text'].apply(lambda x: x[:100] + '...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92a1a67-1e9e-4dde-ab5f-f24c0fac905d",
   "metadata": {},
   "source": [
    "#### Step 4.3 üìÇ Load and Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3b55eaf-155b-4afa-a4e0-eead65c2fb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fine_llm = df[['full_text', 'target_text']].dropna().reset_index(drop = True)\n",
    "data = df_fine_llm.sample(1000) # Limit for memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "532ea8d5-a38a-4abd-bff1-2a53563e5842",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to Dataset\n",
    "data_set = Dataset.from_pandas(data)\n",
    "data_set = data_set.train_test_split(test_size = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6deeb447-2737-4924-a855-8da14e1c0b6e",
   "metadata": {},
   "source": [
    "#### Step 4.4 üß† Load Pretrained Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ce7ccd4-2a28-44ad-8045-db7deaac9a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Model (T5-Small for Summarization)\n",
    "model_name = 't5-small'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff0579d-6817-4891-b6f6-8154e79459fc",
   "metadata": {},
   "source": [
    "#### Step 4.5 ‚úÇÔ∏è Tokenize and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec3a58f4-bc32-4ef4-a12c-f3b9d11a2d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = 512\n",
    "max_output_length = 128\n",
    "\n",
    "def preprocess(each_data):\n",
    "    inputs = tokenizer(\n",
    "        each_data['full_text'],\n",
    "        padding = 'max_length',\n",
    "        truncation = True,\n",
    "        max_length = max_input_length\n",
    "    )\n",
    "    targets = tokenizer(\n",
    "        each_data['target_text'],\n",
    "        padding = 'max_length',\n",
    "        truncation = True,\n",
    "        max_length = max_input_length  \n",
    "    )\n",
    "\n",
    "    inputs['labels'] = targets['input_ids']\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb3b19c2-48c2-48ca-9fba-52496b69f2bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e91a081cda34cc1b0b2ad742a0f85e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/900 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73819fc9a8494c71955843d5bdd29814",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_data_set = data_set.map(preprocess, batched = True, remove_columns = ['full_text', 'target_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9cc795-ff49-4557-b36a-cc76e978f9c7",
   "metadata": {},
   "source": [
    "#### Step 4.6 üèãÔ∏è Fine-Tune the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5374af5d-66ae-475b-a25f-f167026f90c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./t5_medical_transcription_summary_finetuned\",\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=3,\n",
    "    logging_dir=\"./logs\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    predict_with_generate=True,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6f0df2b-16a3-41fa-8461-8b1799c77a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n3/1j5nrn9930j2yg8rlrdbgt6c0000gn/T/ipykernel_43075/4167170881.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_data_set['train'],\n",
    "    eval_dataset=tokenized_data_set['test'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer, model=model),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b9f69dc-91d0-4ed4-beba-c53422646740",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1350' max='1350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1350/1350 35:22, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.025078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.760500</td>\n",
       "      <td>0.021025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.026500</td>\n",
       "      <td>0.020387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1350, training_loss=0.29737290099815084, metrics={'train_runtime': 2124.8342, 'train_samples_per_second': 1.271, 'train_steps_per_second': 0.635, 'total_flos': 365422863974400.0, 'train_loss': 0.29737290099815084, 'epoch': 3.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5389eebc-cb8e-4b81-bdeb-3af78e78d1fd",
   "metadata": {},
   "source": [
    "#### Step 4.7 üíæ Save Model & Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e124d24b-a505-47ac-937d-30ed7c916cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('t5_medical_transcription_summary_tokenizer/tokenizer_config.json',\n",
       " 't5_medical_transcription_summary_tokenizer/special_tokens_map.json',\n",
       " 't5_medical_transcription_summary_tokenizer/spiece.model',\n",
       " 't5_medical_transcription_summary_tokenizer/added_tokens.json',\n",
       " 't5_medical_transcription_summary_tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(\"t5_medical_transcription_summary_model\")\n",
    "tokenizer.save_pretrained(\"t5_medical_transcription_summary_tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2aa164-d8a7-4cca-b0ca-7dd7a09f8893",
   "metadata": {},
   "source": [
    "#### Step 4.8. üß™ Testing the Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "40b998a2-6842-42fb-af1e-5853449262b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "# Load the fine-tuned summarization model and tokenizer\n",
    "summarizer = pipeline(\"summarization\", model=\"t5_medical_transcription_summary_model\", tokenizer=\"t5_medical_transcription_summary_tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "945f1e9b-e936-48ae-a0dd-4d73969d4d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Input:  A 23-year-old white female presents with complaint of allergies.SUBJECTIVE:,  This 23-year-old white female presents with complaint of allergies.  She used to have allergies when she lived in Seattle but she thinks they are worse here.  In the past, she has tried Claritin, and Zyrtec.  Both worked for short time but then seemed to lose effectiveness.  She has used Allegra also.  She used that last summer and she began using it again two weeks ago.  It does not appear to be working very well.  S\n",
      "üìù Summary: A 23-year-old white female presents with complaint of allergies.SUBJECTIVE, This . . This a british white woman has complained of allergies .\n"
     ]
    }
   ],
   "source": [
    "test_input = df['full_text'].iloc[0]\n",
    "print(\"üßæ Input:\", test_input[:500])\n",
    "# Generate a summary and print it\n",
    "print(\"üìù Summary:\", summarizer(test_input, max_length=150, min_length=30, do_sample=False)[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "392a8fb7-9192-453d-90fd-76f8d8ba8dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndf['summary'] = df['full_text'][0:50].apply(\\n    lambda x : summarizer(x, max_length=150, min_length=30, do_sample=False)[0]['summary_text'])\\n\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##if you want to summarize all the texts\n",
    "'''\n",
    "df['summary'] = df['full_text'][0:50].apply(\n",
    "    lambda x : summarizer(x, max_length=150, min_length=30, do_sample=False)[0]['summary_text'])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b1cd1f0a-07d2-4759-a974-27ef2811c65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Summary: The patient is a 47-year-old male who presented to the Emergency Department with the sudden onset of severe right back pain that began approximately 2 hours ago . The pain is described as sharp and constant, radiating to the right flank . he reports associated nausea, but denies vomiting. He states the pain has not been relieved by over-the-counter pain medication.\n"
     ]
    }
   ],
   "source": [
    "test = 'Chief Complaint: Severe right back pain History of Present Illness: The patient is a 47-year-old male who presented to the Emergency Department with the sudden onset of severe right back pain that began approximately 2 hours ago. The pain is described as sharp and constant, radiating to the right flank. He reports associated nausea, but denies vomiting. He states the pain has not been relieved by over-the-counter pain medication. He has never experienced similar symptoms before. He denies any recent trauma, fever, or chills. He reports no change in pain with movement, no association with food, and no symptoms of GERD. Past Medical History: The patient has a history of asymptomatic gout, hypertension, hypercholesterolemia, and hypertriglyceridemia. He is currently taking medication for his hypertension, but the name of the medication is unknown at this time. He underwent a TAH with BSO six years ago. Social History: The patient is a non-smoker and reports occasional alcohol intake. Family History: There is a family history of premature CAD (coronary artery disease). Physical Examination: Findings from the physical examination included normal general appearance with the patient in distress, elevated blood pressure, normal heart and respiratory rates, and normal temperature and oxygen saturation. Specific findings included tenderness over the right costovertebral angle. The full physical examination details can be found in the referenced documents. Assessment and Plan: Based on the patients symptoms and a CT scan of the abdomen and pelvis, which showed a 5 mm renal stone, the diagnosis of nephrolithiasis was made. The plan involves admitting the patient for intravenous fluids, pain management, and monitoring for spontaneous stone passage. A urology consult has been requested, and vital signs, pain level, and kidney function will be monitored.'\n",
    "print(\"üìù Summary:\", summarizer(test, max_length=200, min_length=30, do_sample=False)[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "87a3200c-cee9-42f0-a1b8-a0e8b57f7b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 200, but your input_length is only 97. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=48)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Summary: The patient is a 47-year-old male presenting to the emergency department with sudden onset of severe right-sided back pain radiating to the lower abdomen. He reports no trauma . Physical exam reveals right flank tenderness. Vitals are stable. A CT scan is ordered to rule out nephrolithiasis.\n"
     ]
    }
   ],
   "source": [
    "test = 'The patient is a 47-year-old male presenting to the emergency department with sudden onset of severe right-sided back pain radiating to the lower abdomen. He reports no trauma but mentions prior episodes of kidney stones. Physical exam reveals right flank tenderness. Vitals are stable. Urinalysis shows microscopic hematuria. A CT scan is ordered to rule out nephrolithiasis.'\n",
    "print(\"üìù Summary:\", summarizer(test, max_length=200, min_length=30, do_sample=False)[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5e023472-13f0-4f99-b7fe-5de86ca00e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 130, but your input_length is only 109. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=54)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Summary: A 26-year-old female with a known history of asthma presented with shortness of breath, wheezing, and coughing for the past two days . Symptoms worsened overnight despite using her albuterol inhaler .\n"
     ]
    }
   ],
   "source": [
    "test = 'A 26-year-old female with a known history of asthma presented with shortness of breath, wheezing, and coughing for the past two days. Symptoms worsened overnight despite using her albuterol inhaler. On examination, she had bilateral wheezing and accessory muscle use. Oxygen saturation was 92% on room air. She was treated with nebulized bronchodilators, corticosteroids, and oxygen therapy.'\n",
    "print(\"üìù Summary:\", summarizer(test, max_length=130, min_length=30, do_sample=False)[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e2f783fa-7f78-4efe-b374-af81e4b55917",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 130, but your input_length is only 97. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=48)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Summary: The patient is a 59-year-old male with hypertension and hyperlipidemia who presented with chest pain radiating to the left arm, associated with diaphoresis and nausea. ECG showed ST elevations in the anterior leads. Troponin levels were elevated.\n"
     ]
    }
   ],
   "source": [
    "test = 'The patient is a 59-year-old male with hypertension and hyperlipidemia who presented with chest pain radiating to the left arm, associated with diaphoresis and nausea. ECG showed ST elevations in the anterior leads. Troponin levels were elevated. The cardiology team was consulted, and the patient was taken for emergent cardiac catheterization which revealed a 90% occlusion in the LAD.'\n",
    "print(\"üìù Summary:\", summarizer(test, max_length=130, min_length=30, do_sample=False)[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6731ab07-941e-45f4-a8b6-5f01fbe6f52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 130, but your input_length is only 100. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Summary: a 65-year-old female with poorly controlled type 2 diabetes mellitus presented with a non-healing ulcer on the plantar surface of her right foot for three weeks. The area is erythematous with purulent drainage. Wound culture grew Staphylococcus aureus. She was started on IV antibiotics, and surgical debridement was scheduled .\n"
     ]
    }
   ],
   "source": [
    "test = 'A 65-year-old female with poorly controlled type 2 diabetes mellitus presented with a non-healing ulcer on the plantar surface of her right foot for three weeks. The area is erythematous with purulent drainage. Wound culture grew Staphylococcus aureus. She was started on IV antibiotics, and surgical debridement was scheduled. Glycemic control is being optimized during hospitalization.'\n",
    "print(\"üìù Summary:\", summarizer(test, max_length=130, min_length=30, do_sample=False)[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707d37d6-e2b5-4791-9038-49b0405e99b0",
   "metadata": {},
   "source": [
    "## üîö Final Conclusion\n",
    "- ‚úÖ RAG clearly outperforms naive LLM prompting, especially when dealing with large, similar medical texts.\n",
    "- üîÅ A loop-ready solution for updating vector stores allows real-time summarization of newly entered records.\n",
    "- üì¶ This architecture can scale from offline summarization to live AI assistants in hospitals.\n",
    "This solution is powerful for clinical NLP, healthcare AI, and document automation workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2386897-2d45-49cc-b397-2d1e7a7d8c81",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
