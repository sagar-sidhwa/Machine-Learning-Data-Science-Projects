# ğŸ¦ Bank IT Support Ticket Classification â€” Predicting Customer Intent

This project classifies **customer support tickets** in a banking domain into predefined **intent categories** using sentence embeddings and traditional machine learning models.

---

## ğŸ§  Objective

To predict the **intent** behind a customerâ€™s support ticket by analyzing the textual description of the issue, enabling faster routing and resolution in a bank's IT support system.

---

## ğŸ“ Dataset (Link - https://huggingface.co/datasets/rbojja/labelled_bank_support_dataset)
- Source: HuggingFace Dataset Hub (`rbojja/labelled_bank_support_dataset`)
- Fields: `domain`, `subdomain`, `category`, `example`, `intent`

## ğŸ“ Dataset Overview

- **Source**: HuggingFace Dataset Hub  
  â†’ [`rbojja/labelled_bank_support_dataset`](https://huggingface.co/datasets/rbojja/labelled_bank_support_dataset)
- **Fields**:
  - `domain`
  - `subdomain`
  - `category`
  - `example` (text)
  - `intent` (target label)

---

## ğŸ§± Project Steps

### 1. ğŸ“¦ Data Cleaning & Preprocessing
- Removed low-frequency intent classes (appearing <2 times)
- Cleaned text data, ensured type consistency

### 2. ğŸ”¤ Embedding Generation
- Used **`sentence-transformers`** (`all-MiniLM-L6-v2`) to convert support text into numerical vectors (dense embeddings)

### 3. ğŸ¤– Model Building
Trained and evaluated the following classifiers on the embeddings:
- Logistic Regression
- SGD Classifier
- Random Forest
- MLP Classifier

### 4. ğŸ”§ Hyperparameter Tuning
- Used `GridSearchCV` for model selection and tuning
- Applied **Stochastic Gradient Descent (SGD)** where applicable (e.g., in SGDClassifier, MLP, and Logistic Regression with `solver='saga'`)

---

## ğŸ§ª Evaluation Metrics

Evaluated using:
- **Accuracy**
- **Precision**
- **Recall**
- **F1-score**
- Nearest Neighbors lookup for qualitative inspection (KNN)

---

## ğŸ“Š Results Snapshot

| Model              | Notes                                      |
|-------------------|---------------------------------------------|
| Logistic Regression | Balanced performance with `saga` solver  |
| SGD Classifier     | Fast, tunable, worked well with embeddings |
| Random Forest      | Captured non-linear patterns               |
| MLP Classifier     | SGD used as optimizer, moderate accuracy   |

> âš ï¸ Model performance was limited by **intent overlap** and **possible label noise** in the dataset.

---

## ğŸ“Œ Tech Stack

- **Language**: Python  
- **Libraries**:  
  - `sentence-transformers` for embeddings  
  - `scikit-learn` for modeling and tuning  
  - `pandas`, `numpy` for data handling  
  - `matplotlib`, `seaborn` for visualization  

---

## ğŸš€ Future Work

- Add few-shot LLM-based intent classification (OpenAI or Cohere)
- Explore clustering for semi-supervised intent discovery
- Improve preprocessing for synonyms and phrase grouping
- Introduce explainability (e.g., SHAP for feature importance)

---

## ğŸ”§ Technologies Used
- Python
- SentenceTransformers
- Scikit-learn
- Pandas, NumPy, Seaborn

## âš™ï¸ Methodology
1. Extract embeddings using `sentence-transformers`
2. Apply classifiers: Logistic Regression, Random Forest
3. Evaluate with accuracy, precision, recall, F1-score

## âœ… Outcome
Achieved moderate classification accuracy due to potential label noise and intent overlaps.

---

## ğŸ‘¨â€ğŸ’» Author

[Sagar Sidhwa] - 
ML / AI Engineer
MS in CS â€” AI Track  From Binghamton University 
Focusing ML, and end-to-end real-world projects 
Open to collaboration!
